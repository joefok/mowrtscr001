<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Gesture Tetris</title>

  <!-- âœ… Load libraries correctly -->
  https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js</script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection@2.0.1se-detection.min.js</script>
  https://cdn.jsdelivr.net/npm/@mediapipe/hands@latest</script>

  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #111;
      font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
      color: white;
    }
    canvas {
      width: 100vw;
      height: 80vh;
      background: #000;
      display: block;
    }
    video {
      position: fixed;
      bottom: 10px;
      right: 10px;
      width: 96px;
      height: 72px;
      border: 2px solid #0ff;
      z-index: 10;
      /* Mirror the preview so it feels natural */
      transform: scaleX(-1);
    }
    #status {
      position: fixed;
      top: 10px;
      left: 10px;
      background: rgba(0,0,0,0.6);
      padding: 8px 12px;
      border-radius: 6px;
      font-size: 14px;
      z-index: 10;
      max-width: 90vw;
      white-space: pre-wrap;
    }
  </style>
</head>
<body>
  <div id="status">Loading TensorFlow & Camera...</div>
  <canvas id="tetris"></canvas>
  <video id="camera" autoplay playsinline muted></video>

  <script>
    window.addEventListener('DOMContentLoaded', async () => {
      const canvas = document.getElementById('tetris');
      const ctx = canvas.getContext('2d');
      const statusDiv = document.getElementById('status');
      const video = document.getElementById('camera');

      // Board setup
      const TILE = 30;
      const COLS = 10;
      const ROWS = 20;
      canvas.width = COLS * TILE;
      canvas.height = ROWS * TILE;

      // Simple "T" piece
      let piece = [
        [1, 1, 1],
        [0, 1, 0],
      ];
      let position = { x: 3, y: 0 };

      // Left/right gesture handling
      let lastMove = 0;
      const MOVE_COOLDOWN_MS = 180; // throttle horizontal moves

      function clampX() {
        const maxX = COLS - piece[0].length;
        if (position.x < 0) position.x = 0;
        if (position.x > maxX) position.x = maxX;
      }

      function draw() {
        ctx.fillStyle = '#000';
        ctx.fillRect(0, 0, canvas.width, canvas.height);

        ctx.fillStyle = 'cyan';
        for (let y = 0; y < piece.length; ++y) {
          for (let x = 0; x < piece[y].length; ++x) {
            if (piece[y][x]) {
              ctx.fillRect((position.x + x) * TILE, (position.y + y) * TILE, TILE, TILE);
            }
          }
        }

        // Optional: draw grid lines for clarity
        ctx.strokeStyle = 'rgba(255,255,255,0.08)';
        for (let x = 1; x < COLS; x++) {
          ctx.beginPath();
          ctx.moveTo(x * TILE, 0);
          ctx.lineTo(x * TILE, canvas.height);
          ctx.stroke();
        }
        for (let y = 1; y < ROWS; y++) {
          ctx.beginPath();
          ctx.moveTo(0, y * TILE);
          ctx.lineTo(canvas.width, y * TILE);
          ctx.stroke();
        }
      }

      function update() {
        position.y++;
        if (position.y > ROWS - piece.length) position.y = 0;
        draw();
      }

      // Start the falling loop
      let fallTimer = null;

      // Utilities
      async function readyVideoPlayback() {
        // Start camera and wait for video to be ready
        statusDiv.textContent = "Requesting camera access...";
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "user" },
          audio: false
        });
        video.srcObject = stream;

        // Make sure metadata is ready before detection
        await new Promise((resolve) => {
          if (video.readyState >= 2) return resolve();
          video.onloadeddata = () => resolve();
        });

        // Some browsers still need an explicit play()
        try { await video.play(); } catch (_) {}
      }

      async function setupTF() {
        // Try WebGL first; fallback to CPU if needed
        statusDiv.textContent = "Setting up TensorFlow backend...";
        try {
          await tf.setBackend('webgl');
          await tf.ready();
        } catch (e) {
          console.warn("WebGL backend failed, falling back to CPU", e);
          await tf.setBackend('cpu');
          await tf.ready();
        }
      }

      async function main() {
        try {
          if (!navigator.mediaDevices?.getUserMedia) {
            throw new Error("getUserMedia is not supported (use HTTPS and a modern browser).");
          }

          await setupTF();

          statusDiv.textContent = "Creating hand detector...";
          const model = handPoseDetection.SupportedModels.MediaPipeHands;
          const detectorConfig = {
            runtime: 'mediapipe',
            modelType: 'lite',
            // MediaPipe assets will be fetched from here
            solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/hands@latest',
          };
          const detector = await handPoseDetection.createDetector(model, detectorConfig);

          await readyVideoPlayback();

          statusDiv.textContent = "Camera access granted. Gesture module active.";
          draw();
          fallTimer = setInterval(update, 500);

          // Main detection loop
          async function detect() {
            try {
              // Flip horizontally to match mirrored preview
              const hands = await detector.estimateHands(video, { flipHorizontal: true });

              if (hands.length > 0) {
                const keypoints = hands[0].keypoints || [];
                const wrist = keypoints.find(k => k.name === 'wrist');
                const indexTip = keypoints.find(k => k.name === 'index_finger_tip');

                if (wrist && indexTip) {
                  const dx = indexTip.x - wrist.x; // >0 means index is to the right of wrist (after flip)
                  const now = performance.now();

                  if (now - lastMove > MOVE_COOLDOWN_MS) {
                    if (dx > 30) {
                      position.x += 1;
                      lastMove = now;
                    } else if (dx < -30) {
                      position.x -= 1;
                      lastMove = now;
                    }
                    clampX();
                    draw();
                  }
                }
              }
            } catch (err) {
              statusDiv.textContent = "Error during hand detection:\n" + (err?.stack || err);
              console.error("Hand detection error:", err);
            }
            requestAnimationFrame(detect);
          }

          detect();
        } catch (err) {
          statusDiv.textContent = "Startup error:\n" + (err?.stack || err);
          console.error("Startup error:", err);
        }
      }

      main();
    });
  </script>
</body>
